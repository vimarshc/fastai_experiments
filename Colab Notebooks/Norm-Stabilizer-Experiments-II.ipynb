{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Norm-Stabilizer-Experiments-II.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"GNy7WHZ3WiAQ","colab_type":"code","colab":{}},"source":["from fastai.text import * \n","from fastai import * "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KZnoWhVWZOYT","colab_type":"text"},"source":["\n","**[1][Regularizing RNNs by Stabilizing Activations](https://arxiv.org/abs/1511.08400)**\n"," - by David Krueger, Roland Memisevic\n","\n"]},{"cell_type":"code","metadata":{"id":"1Y4L-39aVr8M","colab_type":"code","outputId":"461222f7-a815-4750-8d1c-7645ac26ee19","executionInfo":{"status":"ok","timestamp":1572813322669,"user_tz":-330,"elapsed":579,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}},"colab":{"base_uri":"https://localhost:8080/","height":281}},"source":["\n","bs=48\n","path = untar_data(URLs.IMDB)\n","path.ls()\n","data_lm = (TextList.from_folder(path)\n","           #Inputs: all the text files in path\n","            .filter_by_folder(include=['train', 'test', 'unsup']) \n","           #We may have other temp folders that contain text files so we only keep what's in train and test\n","            .split_by_rand_pct(0.1)\n","           #We randomly split and keep 10% (10,000 reviews) for validation\n","            .label_for_lm()           \n","           #We want to do a language model so we label accordingly\n","            .databunch(bs=bs))\n","data_lm.save('data_lm.pkl')\n","\n","data_lm = load_data(path, 'data_lm.pkl', bs=bs)\n","data_lm.show_batch()"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>idx</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>breaking the xxmaj ice . \" xxmaj seriously , the only good thing about this film was seeing the original xxmaj hanson xxmaj brothers reprise their roles , which was not nearly enough to save it . a life - size cardboard cutout of xxmaj paul xxmaj newman has more acting talent than xxmaj steven xxmaj baldwin . xxmaj and i 'm being generous . xxmaj only if you have</td>\n","    </tr>\n","    <tr>\n","      <td>1</td>\n","      <td>award , and surprisingly , it did n't work ( unlike xxmaj dustin xxmaj hoffman 's one - note performance in xxmaj rain xxmaj man or xxmaj al xxmaj pacino 's self - parody in xxmaj scent of a xxmaj woman ) . xxmaj michael xxmaj apted should know better , having done a half - decent job portraying mountain life in xxmaj coal xxmaj miner 's xxmaj daughter .</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>he keeps ignoring how he 's being treated by the xxmaj roberts of the world , all of who are bleeding him white ( no pun intended )  and , in the finale , to the point of forcing xxmaj davis to take a dive in his last bout and retire rich . xxmaj does he do it or does he redeem his honor ? i 'll let you</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>the world . xxbos i was very fortunate last night , as i had a chance to see xxup xxunk in a sneak preview almost half a year prior to its scheduled start over here in xxmaj austria . i was instantly thrilled as i heard a lot about this ambitious project in the past two years ! xxmaj and i learned a lot last night ... xxmaj for starters</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>zoo in xxmaj budapest \" and \" xxmaj man 's xxmaj castle \" would cement her position as the xxmaj depression 's most desirable waif , the pin - up girl of the bread lines . xxmaj with the xxunk comedienne xxmaj winnie xxmaj lightner as her wisecracking pal and xxmaj guy xxmaj kibbee , criminally wasted as xxmaj lightner 's swain . xxbos xxmaj as i saw the movie</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"7obInUTIWspL","colab_type":"code","colab":{}},"source":["learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n","# learn.lr_find()\n","# learn.recorder.plot(skip_end=15)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ws0aGAbKW3HF","colab_type":"code","colab":{}},"source":["learn.save_encoder('fine_tuned_enc')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o8xMj8o9XDo1","colab_type":"code","outputId":"3899aaca-147c-440a-b31e-6c66f552fab5","executionInfo":{"status":"ok","timestamp":1572813447837,"user_tz":-330,"elapsed":703,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}},"colab":{"base_uri":"https://localhost:8080/","height":297}},"source":["path = untar_data(URLs.IMDB)\n","data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n","             #grab all the text files in path\n","             .split_by_folder(valid='test')\n","             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n","             .label_from_folder(classes=['neg', 'pos'])\n","             #label them all with their folders\n","             .databunch(bs=bs))\n","\n","data_clas.save('data_clas.pkl')\n","data_clas = load_data(path, 'data_clas.pkl', bs=bs)\n","data_clas.show_batch()"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>text</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos * ! ! - xxup spoilers - ! ! * \\n \\n  xxmaj before i begin this , let me say that i have had both the advantages of seeing this movie on the big screen and of having seen the \" xxmaj authorized xxmaj version \" of this movie , remade by xxmaj stephen xxmaj king , himself , in 1997 . \\n \\n  xxmaj both</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos * * * xxmaj warning - this review contains \" plot spoilers , \" though nothing could \" spoil \" this movie any more than it already is . xxmaj it really xxup is that bad . * * * \\n \\n  xxmaj before i begin , i 'd like to let everyone know that this definitely is one of those so - incredibly - bad - that</td>\n","      <td>neg</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos i felt duty bound to watch the 1983 xxmaj timothy xxmaj dalton / xxmaj zelah xxmaj clarke adaptation of \" xxmaj jane xxmaj eyre , \" because i 'd just written an article about the 2006 xxup bbc \" xxmaj jane xxmaj eyre \" for xxunk . \\n \\n  xxmaj so , i approached watching this the way i 'd approach doing homework . \\n \\n  i</td>\n","      <td>pos</td>\n","    </tr>\n","    <tr>\n","      <td>xxbos xxmaj waitress : xxmaj honey , here 's them eggs you ordered . xxmaj honey , like bee , get it ? xxmaj that 's called pointless foreshadowing . \\n \\n  xxmaj edward xxmaj basket : xxmaj huh ? ( xxmaj on the road ) xxmaj basket : xxmaj here 's your doll back , little girl . xxmaj you really should n't be so careless with your</td>\n","      <td>neg</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"pkH0vcPwcSxk","colab_type":"text"},"source":["First using fastai's basic methodology we've created a language model fine tuned on the Wikipedia text. After that we've established a baseline using the fastai's fit_one_cycle policy. "]},{"cell_type":"code","metadata":{"id":"mZ7dISKjXM2E","colab_type":"code","outputId":"8b0e411d-c957-47e2-f1a7-1d046c3ec228","colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n","learn.load_encoder('fine_tuned_enc')\n","# learn.lr_find()\n","# learn.recorder.plot()\n","learn.fit_one_cycle(5, 2e-2, moms=(0.8,0.7))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='1' class='' max='5', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      20.00% [1/5 10:06<40:24]\n","    </div>\n","    \n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.471733</td>\n","      <td>0.457118</td>\n","      <td>0.777040</td>\n","      <td>10:06</td>\n","    </tr>\n","  </tbody>\n","</table><p>\n","\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='240' class='' max='521', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      46.07% [240/521 03:09<03:41]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"YuA-ERRodyJK","colab_type":"text"},"source":["\n","#### **BASELINE** ####\n","The baseline I have established does not include fine tuning the language model on the IMDB data. I simply loaded the encoder without fine tuning the language model at all. \n","\n","\n","#### **fastai's existing fine tuning techniques** ####\n","fastai already uses a couple of techniques for stabilizing RNNs. \n","Those are defined [here](https://github.com/fastai/fastai/blob/master/fastai/callbacks/rnn.py). \n","\n","fastai documentation for the fine tuning techniques for `fastai.text` can  be found [here](https://docs.fast.ai/callbacks.rnn.html): \n","\n","These techniques are adopted from this paper:\n","\n","**[2][Regularizing and Optimizing LSTM Language Models](https://arxiv.org/abs/1708.02182)**\n"," - Stephen Merity, Nitish Shirish Keskar, Richard Socher\n","\n","**[2]** Introduces a technique called `Temporal Activation Regularization (TAR)`\n","\n"," The TAR technique is essentially adding the following term to the loss (thus it exists in the callback `backward_begin`): \n","\n"," `extra_loss_regularization_term = β L2(ht − ht+1)`\n","\n"," Where `ht` is the hidden state at timestep `t`\n","\n","For those who are confused by the fancy terms (as I was) [here](https://en.wikipedia.org/wiki/Norm_(mathematics)#p-norm) is the definition if L2\n","\n"," [2] also states:\n","`As in Merity et al. (2017),\n","the AR and TAR loss are only applied to the output of the\n","final RNN layer as opposed to being applied to all layers.`\n","\n","The Norm Stabilizer paper introduces a technique similar to TAR from the paper above. So it implement this paper we will have to override the existing callback. \n","\n","Below is the callback implemented by fastai for reference. \n","\n"]},{"cell_type":"code","metadata":{"id":"hmIvYNIOdxj-","colab_type":"code","colab":{}},"source":["class RNNTrainer(LearnerCallback):\n","    \"`Callback` that regroups lr adjustment to seq_len, AR and TAR.\"\n","    def __init__(self, learn:Learner, alpha:float=0., beta:float=0.):\n","        super().__init__(learn)\n","        self.not_min += ['raw_out', 'out']\n","        self.alpha,self.beta = alpha,beta\n","        \n","    def on_epoch_begin(self, **kwargs):\n","        \"Reset the hidden state of the model.\"\n","        self.learn.model.reset()\n","\n","    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n","        \"Save the extra outputs for later and only returns the true output.\"\n","        self.raw_out,self.out = last_output[1],last_output[2]\n","        return {'last_output': last_output[0]}\n","\n","    def on_backward_begin(self, last_loss:Rank0Tensor, last_input:Tensor, **kwargs):\n","        \"Apply AR and TAR to `last_loss`.\"\n","        \n","        #AR \n","        if self.alpha != 0.:  last_loss += self.alpha * self.out[-1].float().pow(2).mean()\n","\n","\n","        # TAR\n","        if self.beta != 0.:\n","            h = self.raw_out[-1]\n","            if len(h)>1: last_loss += self.beta * (h[:,1:] - h[:,:-1]).float().pow(2).mean() #L2\n","\n","\n","        return {'last_loss': last_loss}\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3iIotWW7iiT6","colab_type":"text"},"source":["####**Modifications**####\n","\n","We are going to have to replace the existing callback with a callback which also adds the norm-stabilizer term. \n","\n","####**Norm Stabilizer**####\n","The term reccomended by [1] is as follows: \n","`(β/T)* SIGMA[Across T](L2(ht) - L2(ht-1)^2`\n","\n","I have modified the RNNTrainer to add the norm-stabilizer below. \n"]},{"cell_type":"code","metadata":{"id":"0IXEHsIGcPDJ","colab_type":"code","colab":{}},"source":["def apply_ar(alpha,out): return alpha * out[-1].float().pow(2).mean()\n","\n","def apply_tar(beta,h): return beta * (h[:,1:] - h[:,:-1]).float().pow(2).mean()\n","\n","def apply_normstable(beta,h): return beta/h.shape[1] *  (h[:,1:].pow(2).sum().sqrt() - h[:,:-1].pow(2).sum().sqrt()).float().pow(2)\n","\n","class RNNTrainerNorm(LearnerCallback):\n","    def __init__(self, learn:Learner, alpha:float=2., beta:float=1., beta_norm:float=50.):\n","        super().__init__(learn)\n","        self.not_min += ['raw_out', 'out']\n","        self.alpha,self.beta,self.beta_norm = alpha,beta,beta_norm\n","        \n","    def on_epoch_begin(self, **kwargs):\n","        \"Reset the hidden state of the model.\"\n","        self.learn.model.reset()\n","\n","    def on_loss_begin(self, last_output:Tuple[Tensor,Tensor,Tensor], **kwargs):\n","        \"Save the extra outputs for later and only returns the true output.\"\n","        self.raw_out,self.out = last_output[1],last_output[2]\n","        return {'last_output': last_output[0]}\n","\n","    def on_backward_begin(self, last_loss:Rank0Tensor, last_input:Tensor, **kwargs):\n","        import pdb;pdb.set_trace()\n","        \"Apply AR and TAR to `last_loss`.\"\n","        #AR and TAR\n","        if self.alpha != 0.:  last_loss += apply_ar(self.alpha,self.out)\n","        if self.beta != 0.:\n","            h = self.raw_out[-1]\n","            if len(h)>1: last_loss += apply_tar(self.beta,h)\n","\n","        if self.beta_norm != 0.:\n","            h = self.raw_out[-1]\n","            if len(h)>1: last_loss += apply_normstable(self.beta_norm,h)        \n","        \n","        return {'last_loss': last_loss}\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FnPZK-4dq7hZ","colab_type":"code","colab":{}},"source":["def has_params(m:nn.Module)->bool:\n","    \"Check if `m` has at least one parameter\"\n","    return len(list(m.parameters())) > 0\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cOKNPqLUlxLv","colab_type":"code","colab":{}},"source":["modules = [m for m in flatten_model(learn.model) if has_params(m)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p08raE6Ulyk-","colab_type":"code","outputId":"b1e83e15-c2ab-433d-a09f-a39b4cd89d15","executionInfo":{"status":"ok","timestamp":1572808185336,"user_tz":-330,"elapsed":1560,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["modules"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Embedding(60000, 400, padding_idx=1),\n"," Embedding(60000, 400, padding_idx=1),\n"," LSTM(400, 1152, batch_first=True),\n"," ParameterModule(),\n"," LSTM(1152, 1152, batch_first=True),\n"," ParameterModule(),\n"," LSTM(1152, 400, batch_first=True),\n"," ParameterModule(),\n"," BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," Linear(in_features=1200, out_features=50, bias=True),\n"," BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," Linear(in_features=50, out_features=2, bias=True)]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"BOpnhoozrrVJ","colab_type":"code","colab":{}},"source":["def requires_grad_bool(m:nn.Module)->Optional[bool]:\n","    ps = list(m.parameters())\n","    return ps[0].requires_grad\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"U-tqrb0OrE0V","colab_type":"code","outputId":"0b6cd267-26cb-4644-f095-e2d7849381e3","executionInfo":{"status":"ok","timestamp":1572809403763,"user_tz":-330,"elapsed":1331,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["for it in modules:\n","  print(requires_grad_bool(it),it)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["False Embedding(60000, 400, padding_idx=1)\n","False Embedding(60000, 400, padding_idx=1)\n","False LSTM(400, 1152, batch_first=True)\n","False ParameterModule()\n","False LSTM(1152, 1152, batch_first=True)\n","False ParameterModule()\n","False LSTM(1152, 400, batch_first=True)\n","False ParameterModule()\n","True BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","True Linear(in_features=1200, out_features=50, bias=True)\n","True BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","True Linear(in_features=50, out_features=2, bias=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GezBt-PhsLdR","colab_type":"code","colab":{}},"source":["learn.freeze_to(-2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ujwl9Y5BsNCP","colab_type":"code","colab":{}},"source":["modules = [m for m in flatten_model(learn.model) if has_params(m)]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VUJYuTv6wELd","colab_type":"code","outputId":"842ff7dd-1a9a-4db0-8e71-a8a3522c53be","executionInfo":{"status":"ok","timestamp":1572809502473,"user_tz":-330,"elapsed":1133,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}},"colab":{"base_uri":"https://localhost:8080/","height":230}},"source":["for it in modules:\n","  print(requires_grad_bool(it),it)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["False Embedding(60000, 400, padding_idx=1)\n","False Embedding(60000, 400, padding_idx=1)\n","False LSTM(400, 1152, batch_first=True)\n","False ParameterModule()\n","False LSTM(1152, 1152, batch_first=True)\n","False ParameterModule()\n","True LSTM(1152, 400, batch_first=True)\n","True ParameterModule()\n","True BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","True Linear(in_features=1200, out_features=50, bias=True)\n","True BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","True Linear(in_features=50, out_features=2, bias=True)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2_JzEmjwMUt","colab_type":"code","outputId":"39b7e897-3d08-49cc-dd9c-13e9d767a1f1","executionInfo":{"status":"ok","timestamp":1572810503194,"user_tz":-330,"elapsed":84677,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}},"colab":{"base_uri":"https://localhost:8080/","height":94}},"source":["learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n","learn.load_encoder('fine_tuned_enc')\n","learn.freeze_to(-2)\n","learn.lr_find()\n","learn.recorder.plot()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      0.00% [0/1 00:00<00:00]\n","    </div>\n","    \n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>\n","\n","    <div>\n","        <style>\n","            /* Turns off some styling */\n","            progress {\n","                /* gets rid of default border in Firefox and Opera. */\n","                border: none;\n","                /* Needs to be in here for Safari polyfill so background images work as expected. */\n","                background-size: auto;\n","            }\n","            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","                background: #F44336;\n","            }\n","        </style>\n","      <progress value='28' class='' max='520', style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      5.38% [28/520 09:27<2:46:12 0.8052]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dhNl36NqzLdb","colab_type":"code","outputId":"168ba350-905f-4a70-c1d1-5007612ee312","executionInfo":{"status":"ok","timestamp":1572811360380,"user_tz":-330,"elapsed":768653,"user":{"displayName":"Vimarsh Chaturvedi","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA5T0kFhYT-TWqP6SnmS0s4ZarLWqT4RtqKIvBxxA=s64","userId":"08007523027797049436"}},"colab":{"base_uri":"https://localhost:8080/","height":77}},"source":["learn.fit_one_cycle(5, 1e-3, moms=(0.8,0.7))"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/html":["<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: left;\">\n","      <th>epoch</th>\n","      <th>train_loss</th>\n","      <th>valid_loss</th>\n","      <th>accuracy</th>\n","      <th>time</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>0</td>\n","      <td>0.402022</td>\n","      <td>0.315708</td>\n","      <td>0.866360</td>\n","      <td>12:47</td>\n","    </tr>\n","  </tbody>\n","</table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"aS-DTVjM0Q1S","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}